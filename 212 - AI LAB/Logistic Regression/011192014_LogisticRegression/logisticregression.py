# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xgn6Ug7SdUF0mVWrpk7VXLLW1oQo15st
"""

from sklearn import datasets
import random
import numpy as np
from sklearn.model_selection import train_test_split

iris = datasets.load_iris()
X = iris.data[:, :2]
y = (iris.target != 0) * 1

train_ratio = 0.70
validation_ratio = 0.15
test_ratio = 0.15

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio)
X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio / (test_ratio + validation_ratio))

X_train = np.insert(X_train, 0, 1.0, axis=1)
X_val = np.insert(X_val, 0, 1.0, axis=1)
X_test = np.insert(X_test, 0, 1.0, axis=1)

theta = np.random.rand(3, )
print(theta)

lr = 0.001
train_loss = []

row, column = X_train.shape
for i in range(0, 1000):
    TJ = 0
    for j in range(0, row):
        Z = np.dot(X_train[j], theta)
        h = 1.0 / (1 + np.exp(-Z))
        J = (-y_train[j] * np.log(h)) - ((1 - y_train[j]) * (np.log(1 - h)))
        TJ = TJ + J
        dv = np.dot(X_train[j], (h - y_train[j]))
        theta = theta - (dv * lr)
    TJ = TJ / row
    train_loss.append(TJ)

print(theta)
print(train_loss)

import matplotlib.pyplot as plt

plt.plot(range(0, 1000), train_loss)
plt.show()

correct = 0

value, column = X_test.shape
for i in range(0, value):
    Z = np.dot(X_test[i], theta)
    h = 1.0 / (1 + np.exp(-Z))
    if h >= 0.5:
        h = 1
    else:
        h = 0
    if h == y_test[i]:
        correct = correct + 1
val_acc = (correct / value) * 100
print("Accuracy: ", val_acc, "%")
